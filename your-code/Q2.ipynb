{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to enhance the `get_bow_from_docs` function so that it will work with HTML webpages. In HTML, there are a lot of messy codes such as HTML tags, Javascripts, [unicodes](https://www.w3schools.com/charsets/ref_utf_misc_symbols.asp) that will mess up your bag of words. We need to clean up those junk before generating BoW.\n",
    "\n",
    "Next, what you will do is to define several new functions each of which is specialized to clean up the HTML codes in one aspect. For instance, you can have a `strip_html_tags` function to remove all HTML tags, a `remove_punctuation` function to remove all punctuation, a `to_lower_case` function to convert string to lowercase, and a `remove_unicode` function to remove all unicodes.\n",
    "\n",
    "Then in your `get_bow_from_doc` function, you will call each of those functions you created to clean up the HTML before you generate the corpus.\n",
    "\n",
    "Note: Please use Python string operations and regular expression only in this lab. Do not use extra libraries such as `beautifulsoup` because otherwise you loose the purpose of practicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import operator\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your string handling functions below\n",
    "# Minimal 3 functions\n",
    "def strip_html_tags(corpus):\n",
    "    \"\"\"Remove html tags from a string\"\"\"\n",
    "    corpus = re.compile('<.*?>')\n",
    "    return re.sub(corpus, '', doc)\n",
    "def remove_punctuation(corpus): \n",
    "    corpus = [re.sub(\"[^\\w\\w*]\", \" \", doc) for doc in corpus]\n",
    "    return corpus\n",
    "def to_lower_case(corpus):\n",
    "    corpus = [doc.lower() for doc in corpus]\n",
    "    return corpus\n",
    "def remove_unicode(corpus):\n",
    "    corpus = [re.sub(\"[^x20-x7e]+\", \" \", doc) for doc in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, paste your previously written `get_bow_from_docs` function below. Call your functions above at the appropriate place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function\n",
    "def get_bow_from_docs(docs, stop_words=[]):\n",
    "    \n",
    "    # In the function, first define the variables you will use such as `corpus`, `bag_of_words`, and `term_freq`.\n",
    "    \n",
    "    corpus = []\n",
    "    bag_of_words = []\n",
    "    term_freq = []\n",
    "    \n",
    "    \"\"\"\n",
    "    Loop `docs` and read the content of each doc into a string in `corpus`.\n",
    "    Remember to convert the doc content to lowercases and remove punctuation.\n",
    "    \"\"\"\n",
    "\n",
    "    corpus = [open(doc,\"r\").read() for doc in docs]\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Loop `corpus`. Append the terms in each doc into the `bag_of_words` array. The terms in `bag_of_words` \n",
    "    should be unique which means before adding each term you need to check if it's already added to the array.\n",
    "    In addition, check if each term is in the `stop_words` array. Only append the term to `bag_of_words`\n",
    "    if it is not a stop word.\n",
    "    \"\"\"\n",
    "\n",
    "    for doc in corpus:\n",
    "        split = doc.split()\n",
    "        for word in split:\n",
    "            if word not in bag_of_words and word not in stop_words:\n",
    "                bag_of_words.append(word)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Loop `corpus` again. For each doc string, count the number of occurrences of each term in `bag_of_words`. \n",
    "    Create an array for each doc's term frequency and append it to `term_freq`.\n",
    "    \"\"\"\n",
    "\n",
    "    for doc in corpus:\n",
    "        frequency = []\n",
    "        terms = doc.split()\n",
    "        for word in bag_of_words:\n",
    "            frequency.append(terms.count(word))\n",
    "        term_freq.append(frequency)\n",
    "    \n",
    "    # Now return your output as an object\n",
    "    return {\n",
    "        \"bag_of_words\": bag_of_words,\n",
    "        \"term_freq\": term_freq\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, read the content from the three HTML webpages in the `your-codes` directory to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bag_of_words': ['<!DOCTYPE', 'html>', '<html', 'lang=\"en\">', '<head>', '<title>Lorem', 'Ipsum', '-', 'All', 'facts', 'Lipsum', 'generator</title>', '<meta', 'name=\"keywords\"', 'content=\"Lorem', 'Ipsum,', 'Lipsum,', 'Lorem,', 'Text,', 'Generate,', 'Generator,', 'Facts,', 'Information,', 'What,', 'Why,', 'Where,', 'Dummy', 'Typesetting,', 'Printing,', 'Finibus,', 'Bonorum', 'et', 'Malorum,', 'Finibus', 'Extremes', 'Good', 'Evil,', 'Cicero,', 'Latin,', 'Garbled,', 'Scrambled,', 'Lorem', 'ipsum', 'dolor', 'sit', 'amet,', 'dolor,', 'consectetur,', 'adipiscing,', 'elit,', 'sed,', 'eiusmod,', 'tempor,', 'incididunt\"', '/>', 'name=\"description\"', 'content=\"Reference', 'site', 'giving', 'information', 'origins,', 'random', 'generator.\"', 'name=\"viewport\"', 'content=\"width=device-width;', 'initial-scale=1.0\">', 'http-equiv=\"content-type\"', 'content=\"text/html;', 'charset=utf-8\"', '<script', 'type=\"text/javascript\"', 'src=\"//static.amp.services/clients/StreamAMP/Lipsum.js\"></script>', '<link', 'rel=\"icon\"', 'type=\"image/x-icon\"', 'href=\"/favicon.ico\"', 'rel=\"stylesheet\"', 'type=\"text/css\"', 'href=\"/css/020617.css\"', '</head>', '<body>', '<div', 'id=\"Outer\">', 'class=\"banner\"><div', 'id=\"div-gpt-ad-1456148316198-0\">', 'type=\"text/javascript\">googletag.cmd.push(function()', '{', 'googletag.display(\"div-gpt-ad-1456148316198-0\");', '});</script>', '</div></div>', 'id=\"Inner\">', 'id=\"Languages\"><a', 'class=\"hy\"', 'href=\"http://hy.lipsum.com/\">&#1344;&#1377;&#1397;&#1381;&#1408;&#1381;&#1398;</a>', '<a', 'class=\"sq\"', 'href=\"http://sq.lipsum.com/\">Shqip</a>', '<span', 'class=\"ltr\"', 'dir=\"ltr\"><a', 'class=\"xx\"', 'href=\"http://ar.lipsum.com/\"><img', 'src=\"/images/ar.gif\"', 'width=\"18\"', 'height=\"12\"', 'alt=\"&#8235;&#1575;&#1604;&#1593;&#1585;&#1576;&#1610;&#1577;\"', '/></a><a', 'href=\"http://ar.lipsum.com/\">&#8235;&#1575;&#1604;&#1593;&#1585;&#1576;&#1610;&#1577;</a></span>&nbsp;&nbsp;', 'class=\"bg\"', 'href=\"http://bg.lipsum.com/\">&#1041;&#1098;&#1083;&#1075;&#1072;&#1088;&#1089;&#1082;&#1080;</a>', 'class=\"ca\"', 'href=\"http://ca.lipsum.com/\">Catal&agrave;</a>', 'class=\"cn\"', 'href=\"http://cn.lipsum.com/\">&#20013;&#25991;&#31616;&#20307;</a>', 'class=\"hr\"', 'href=\"http://hr.lipsum.com/\">Hrvatski</a>', 'class=\"cs\"', 'href=\"http://cs.lipsum.com/\">&#268;esky</a>', 'class=\"da\"', 'href=\"http://da.lipsum.com/\">Dansk</a>', 'class=\"nl\"', 'href=\"http://nl.lipsum.com/\">Nederlands</a>', 'class=\"en', 'zz\"', 'href=\"http://www.lipsum.com/\">English</a>', 'class=\"et\"', 'href=\"http://et.lipsum.com/\">Eesti</a>', 'class=\"ph\"', 'href=\"http://ph.lipsum.com/\">Filipino</a>', 'class=\"fi\"', 'href=\"http://fi.lipsum.com/\">Suomi</a>', 'class=\"fr\"', 'href=\"http://fr.lipsum.com/\">Fran&ccedil;ais</a>', 'class=\"ka\"', 'href=\"http://ka.lipsum.com/\">&#4325;&#4304;&#4320;&#4311;&#4323;&#4314;&#4312;</a>', 'class=\"de\"', 'href=\"http://de.lipsum.com/\">Deutsch</a>', 'class=\"el\"', 'href=\"http://el.lipsum.com/\">&#917;&#955;&#955;&#951;&#957;&#953;&#954;&#940;</a>', 'href=\"http://he.lipsum.com/\"><img', 'src=\"/images/he.gif\"', 'alt=\"&#8235;&#1506;&#1489;&#1512;&#1497;&#1514;\"', 'href=\"http://he.lipsum.com/\">&#8235;&#1506;&#1489;&#1512;&#1497;&#1514;</a></span>&nbsp;&nbsp;', 'class=\"hi\"', 'href=\"http://hi.lipsum.com/\">&#2361;&#2367;&#2344;&#2381;&#2342;&#2368;</a>', 'class=\"hu\"', 'href=\"http://hu.lipsum.com/\">Magyar</a>', 'class=\"id\"', 'href=\"http://id.lipsum.com/\">Indonesia</a>', 'class=\"it\"', 'href=\"http://it.lipsum.com/\">Italiano</a>', 'class=\"lv\"', 'href=\"http://lv.lipsum.com/\">Latviski</a>', 'class=\"lt\"', 'href=\"http://lt.lipsum.com/\">Lietuvi&scaron;kai</a>', 'class=\"mk\"', 'href=\"http://mk.lipsum.com/\">&#1084;&#1072;&#1082;&#1077;&#1076;&#1086;&#1085;&#1089;&#1082;&#1080;</a>', 'class=\"ms\"', 'href=\"http://ms.lipsum.com/\">Melayu</a>', 'class=\"no\"', 'href=\"http://no.lipsum.com/\">Norsk</a>', 'class=\"pl\"', 'href=\"http://pl.lipsum.com/\">Polski</a>', 'class=\"pt\"', 'href=\"http://pt.lipsum.com/\">Portugu&ecirc;s</a>', 'class=\"ro\"', 'href=\"http://ro.lipsum.com/\">Rom&acirc;na</a>', 'class=\"ru\"', 'href=\"http://ru.lipsum.com/\">Pycc&#1082;&#1080;&#1081;</a>', 'class=\"sr\"', 'href=\"http://sr.lipsum.com/\">&#1057;&#1088;&#1087;&#1089;&#1082;&#1080;</a>', 'class=\"sk\"', 'href=\"http://sk.lipsum.com/\">Sloven&#269;ina</a>', 'class=\"sl\"', 'href=\"http://sl.lipsum.com/\">Sloven&#353;&#269;ina</a>', 'class=\"es\"', 'href=\"http://es.lipsum.com/\">Espa&ntilde;ol</a>', 'class=\"sv\"', 'href=\"http://sv.lipsum.com/\">Svenska</a>', 'class=\"th\"', 'href=\"http://th.lipsum.com/\">&#3652;&#3607;&#3618;</a>', 'class=\"tr\"', 'href=\"http://tr.lipsum.com/\">T&uuml;rk&ccedil;e</a>', 'class=\"uk\"', 'href=\"http://uk.lipsum.com/\">&#1059;&#1082;&#1088;&#1072;&#1111;&#1085;&#1089;&#1100;&#1082;&#1072;</a>', 'class=\"vi\"', 'href=\"http://vi.lipsum.com/\">Ti&#7871;ng', 'Vi&#7879;t</a>', '</div>', '<h1>Lorem', 'Ipsum</h1>', '<h4>\"Neque', 'porro', 'quisquam', 'est', 'qui', 'dolorem', 'quia', 'adipisci', 'velit...\"</h4>', '<h5>\"There', 'loves', 'pain', 'itself,', 'seeks', 'wants', 'it,', 'simply', 'pain...\"</h5>', '<hr', 'id=\"Content\">', 'id=\"Panes\"><div>', '<h2>What', 'Ipsum?</h2>', '<p><strong>Lorem', 'Ipsum</strong>', 'dummy', 'text', 'printing', 'typesetting', 'industry.', \"industry's\", 'standard', '1500s,', 'unknown', 'printer', 'took', 'galley', 'type', 'scrambled', 'make', 'specimen', 'book.', 'It', 'survived', 'centuries,', 'leap', 'electronic', 'typesetting,', 'remaining', 'essentially', 'unchanged.', 'popularised', '1960s', 'release', 'Letraset', 'sheets', 'containing', 'passages,', 'recently', 'desktop', 'publishing', 'software', 'like', 'Aldus', 'PageMaker', 'including', 'versions', 'Ipsum.</p>', '</div><div>', '<h2>Why', 'use', 'it?</h2>', '<p>It', 'long', 'established', 'fact', 'reader', 'distracted', 'readable', 'content', 'page', 'looking', 'layout.', 'The', 'point', 'using', 'more-or-less', 'normal', 'distribution', 'letters,', 'opposed', \"'Content\", 'here,', \"here',\", 'making', 'look', 'English.', 'Many', 'packages', 'web', 'editors', 'default', 'model', 'text,', 'search', \"'lorem\", \"ipsum'\", 'uncover', 'sites', 'infancy.', 'Various', 'evolved', 'years,', 'accident,', 'purpose', '(injected', 'humour', 'like).</p>', '</div><br', '/><div>', '<h2>Where', 'does', 'come', 'from?</h2>', '<p>Contrary', 'popular', 'belief,', 'text.', 'roots', 'piece', 'classical', 'Latin', 'literature', '45', 'BC,', '2000', 'years', 'old.', 'Richard', 'McClintock,', 'professor', 'Hampden-Sydney', 'College', 'Virginia,', 'looked', 'obscure', 'words,', 'passage,', 'going', 'cites', 'word', 'literature,', 'discovered', 'undoubtable', 'source.', 'comes', 'sections', '1.10.32', '1.10.33', '\"de', 'Malorum\"', '(The', 'Evil)', 'written', 'BC.', 'This', 'book', 'treatise', 'theory', 'ethics,', 'Renaissance.', 'line', '\"Lorem', 'amet..\",', 'section', '1.10.32.</p><p>The', 'chunk', 'used', '1500s', 'reproduced', 'interested.', 'Sections', 'Cicero', 'exact', 'original', 'form,', 'accompanied', 'English', '1914', 'translation', 'H.', 'Rackham.</p>', 'I', 'some?</h2>', '<p>There', 'variations', 'passages', 'available,', 'majority', 'suffered', 'alteration', 'injected', 'humour,', 'randomised', 'words', \"don't\", 'slightly', 'believable.', 'If', 'passage', 'need', 'sure', \"isn't\", 'embarrassing', 'hidden', 'middle', 'generators', 'Internet', 'tend', 'repeat', 'predefined', 'chunks', 'necessary,', 'true', 'generator', 'Internet.', 'uses', 'dictionary', '200', 'combined', 'handful', 'sentence', 'structures,', 'generate', 'looks', 'reasonable.', 'generated', 'free', 'repetition,', 'non-characteristic', 'etc.</p>', '<form', 'method=\"post\"', 'action=\"/feed/html\"><table', 'style=\"width:100%\"><tr><td', 'rowspan=\"2\"><input', 'type=\"text\"', 'name=\"amount\"', 'value=\"5\"', 'size=\"3\"', 'id=\"amount\"', '/></td><td', 'rowspan=\"2\"><table', 'style=\"text-align:left\"><tr><td', 'style=\"width:20px\"><input', 'type=\"radio\"', 'name=\"what\"', 'value=\"paras\"', 'id=\"paras\"', 'checked=\"checked\"', '/></td><td><label', 'for=\"paras\">paragraphs</label></td></tr><tr><td', 'value=\"words\"', 'id=\"words\"', 'for=\"words\">words</label></td></tr><tr><td', 'value=\"bytes\"', 'id=\"bytes\"', 'for=\"bytes\">bytes</label></td></tr><tr><td', 'value=\"lists\"', 'id=\"lists\"', 'for=\"lists\">lists</label></td></tr></table></td><td', 'type=\"checkbox\"', 'name=\"start\"', 'id=\"start\"', 'value=\"yes\"', 'style=\"text-align:left\"><label', 'for=\"start\">Start', \"'Lorem<br\", '/>ipsum', \"amet...'</label></td></tr><tr><td></td><td\", 'style=\"text-align:left\"><input', 'type=\"submit\"', 'name=\"generate\"', 'id=\"generate\"', 'value=\"Generate', 'Ipsum\"', '/></td></tr></table></form></div></div><hr', '/><div', 'class=\"boxedTight\"><img', 'src=\"/images/advert.png\"', 'width=\"100%\"', 'alt=\"Advertise\"', '/></div>', 'class=\"boxed\"', 'style=\"color:#ff0000;\"><strong>Translations:</strong>', 'Can', 'help', 'translate', 'foreign', 'language', '?', 'Please', 'email', 'details', 'help.</div>', 'class=\"boxed\">There', 'set', 'mock', 'banners', 'available', 'href=\"/banners\"', 'class=\"lnk\">here</a>', 'colours', 'range', 'banner', 'sizes:<br', '/><a', 'href=\"/banners\"><img', 'src=\"/images/banners/black_234x60.gif\"', 'width=\"234\"', 'height=\"60\"', 'alt=\"Banners\"', 'src=\"/images/banners/grey_234x60.gif\"', 'src=\"/images/banners/white_234x60.gif\"', '/></a></div>', 'class=\"boxed\"><strong>Donate:</strong>', 'regularly', 'Internet,', 'consider', 'donating', 'small', 'sum', 'pay', 'hosting', 'bandwidth', 'bill.', 'There', 'minimum', 'donation,', 'appreciated', 'click', 'target=\"_blank\"', 'href=\"/donate\"', 'donate', 'PayPal.', 'Thank', 'support.</div>', 'id=\"Packages\">', 'rel=\"nofollow\"', 'href=\"https://chrome.google.com/extensions/detail/jkkggolejkaoanbjnmkakgjcdcnpfkgi\">Chrome</a>', 'href=\"https://addons.mozilla.org/en-US/firefox/addon/dummy-lipsum/\">Firefox', 'Add-on</a>', 'href=\"https://github.com/traviskaufman/node-lipsum\">NodeJS</a>', 'href=\"http://ftp.ktug.or.kr/tex-archive/help/Catalogue/entries/lipsum.html\">TeX', 'Package</a>', 'href=\"http://code.google.com/p/pypsum/\">Python', 'Interface</a>', 'href=\"http://gtklipsum.sourceforge.net/\">GTK', 'Lipsum</a>', 'href=\"http://github.com/gsavage/lorem_ipsum/tree/master\">Rails</a>', 'href=\"https://github.com/cerkit/LoremIpsum/\">.NET</a>', 'href=\"http://groovyconsole.appspot.com/script/64002\">Groovy</a>', 'href=\"http://www.layerhero.com/lorem-ipsum-generator/\">Adobe', 'Plugin</a></div>', 'id=\"Translation\">', '<h3>The', '1500s</h3><p>\"Lorem', 'consectetur', 'adipiscing', 'sed', 'eiusmod', 'tempor', 'incididunt', 'ut', 'labore', 'dolore', 'magna', 'aliqua.', 'Ut', 'enim', 'ad', 'minim', 'veniam,', 'quis', 'nostrud', 'exercitation', 'ullamco', 'laboris', 'nisi', 'aliquip', 'ex', 'ea', 'commodo', 'consequat.', 'Duis', 'aute', 'irure', 'reprehenderit', 'voluptate', 'velit', 'esse', 'cillum', 'eu', 'fugiat', 'nulla', 'pariatur.', 'Excepteur', 'sint', 'occaecat', 'cupidatat', 'non', 'proident,', 'sunt', 'culpa', 'officia', 'deserunt', 'mollit', 'anim', 'id', 'laborum.\"</p><h3>Section', 'Malorum\",', 'BC</h3><p>\"Sed', 'perspiciatis', 'unde', 'omnis', 'iste', 'natus', 'error', 'voluptatem', 'accusantium', 'doloremque', 'laudantium,', 'totam', 'rem', 'aperiam,', 'eaque', 'ipsa', 'quae', 'ab', 'illo', 'inventore', 'veritatis', 'quasi', 'architecto', 'beatae', 'vitae', 'dicta', 'explicabo.', 'Nemo', 'ipsam', 'voluptas', 'aspernatur', 'aut', 'odit', 'fugit,', 'consequuntur', 'magni', 'dolores', 'eos', 'ratione', 'sequi', 'nesciunt.', 'Neque', 'est,', 'velit,', 'numquam', 'eius', 'modi', 'tempora', 'incidunt', 'magnam', 'aliquam', 'quaerat', 'voluptatem.', 'minima', 'nostrum', 'exercitationem', 'ullam', 'corporis', 'suscipit', 'laboriosam,', 'aliquid', 'commodi', 'consequatur?', 'Quis', 'autem', 'vel', 'eum', 'iure', 'quam', 'nihil', 'molestiae', 'consequatur,', 'illum', 'quo', 'pariatur?\"</p>', '<h3>1914', 'Rackham</h3>', '<p>\"But', 'explain', 'mistaken', 'idea', 'denouncing', 'pleasure', 'praising', 'born', 'complete', 'account', 'system,', 'expound', 'actual', 'teachings', 'great', 'explorer', 'truth,', 'master-builder', 'human', 'happiness.', 'No', 'rejects,', 'dislikes,', 'avoids', 'pleasure,', 'know', 'pursue', 'rationally', 'encounter', 'consequences', 'extremely', 'painful.', 'Nor', 'pursues', 'desires', 'obtain', 'pain,', 'occasionally', 'circumstances', 'occur', 'toil', 'procure', 'pleasure.', 'To', 'trivial', 'example,', 'undertakes', 'laborious', 'physical', 'exercise,', 'advantage', 'it?', 'But', 'right', 'fault', 'man', 'chooses', 'enjoy', 'annoying', 'consequences,', 'produces', 'resultant', 'pleasure?\"</p>', '<h3>Section', 'BC</h3>', '<p>\"At', 'vero', 'accusamus', 'iusto', 'odio', 'dignissimos', 'ducimus', 'blanditiis', 'praesentium', 'voluptatum', 'deleniti', 'atque', 'corrupti', 'quos', 'quas', 'molestias', 'excepturi', 'occaecati', 'cupiditate', 'provident,', 'similique', 'mollitia', 'animi,', 'laborum', 'dolorum', 'fuga.', 'Et', 'harum', 'quidem', 'rerum', 'facilis', 'expedita', 'distinctio.', 'Nam', 'libero', 'tempore,', 'cum', 'soluta', 'nobis', 'eligendi', 'optio', 'cumque', 'impedit', 'minus', 'quod', 'maxime', 'placeat', 'facere', 'possimus,', 'assumenda', 'repellendus.', 'Temporibus', 'quibusdam', 'officiis', 'debitis', 'necessitatibus', 'saepe', 'eveniet', 'voluptates', 'repudiandae', 'recusandae.', 'Itaque', 'earum', 'hic', 'tenetur', 'sapiente', 'delectus,', 'reiciendis', 'voluptatibus', 'maiores', 'alias', 'consequatur', 'perferendis', 'doloribus', 'asperiores', 'repellat.\"</p>', '<p>\"On', 'hand,', 'denounce', 'righteous', 'indignation', 'dislike', 'men', 'beguiled', 'demoralized', 'charms', 'moment,', 'blinded', 'desire,', 'foresee', 'trouble', 'bound', 'ensue;', 'equal', 'blame', 'belongs', 'fail', 'duty', 'weakness', 'will,', 'saying', 'shrinking', 'pain.', 'These', 'cases', 'perfectly', 'simple', 'easy', 'distinguish.', 'In', 'hour,', 'power', 'choice', 'untrammelled', 'prevents', 'able', 'best,', 'welcomed', 'avoided.', 'certain', 'owing', 'claims', 'obligations', 'business', 'frequently', 'pleasures', 'repudiated', 'annoyances', 'accepted.', 'wise', 'holds', 'matters', 'principle', 'selection:', 'rejects', 'secure', 'greater', 'pleasures,', 'endures', 'pains', 'avoid', 'worse', 'pains.\"</p>', 'id=\"bannerL\"><div', 'id=\"div-gpt-ad-1474537762122-2\">', 'googletag.display(\"div-gpt-ad-1474537762122-2\");', 'id=\"bannerR\"><div', 'id=\"div-gpt-ad-1474537762122-3\">', 'googletag.display(\"div-gpt-ad-1474537762122-3\");', 'class=\"boxed\"><a', 'style=\"text-decoration:none\"', 'href=\"&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#104;&#101;&#108;&#112;&#64;&#108;&#105;&#112;&#115;&#117;&#109;&#46;&#99;&#111;&#109;\">&#104;&#101;&#108;&#112;&#64;&#108;&#105;&#112;&#115;&#117;&#109;&#46;&#99;&#111;&#109;</a><br', 'href=\"/privacy.pdf\"', '/>Privacy', 'Policy</a></div>', 'id=\"div-gpt-ad-1456148316198-1\">', 'googletag.display(\"div-gpt-ad-1456148316198-1\");', '<!--', 'Generated', '0.014', 'seconds', '-->', '</body></html>'], 'term_freq': [[1, 1, 1, 1, 1, 1, 14, 3, 2, 1, 2, 1, 4, 1, 1, 5, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 17, 2, 5, 2, 2, 1, 2, 1, 1, 1, 20, 5, 8, 9, 5, 1, 4, 1, 2, 1, 1, 1, 1, 7, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 10, 1, 2, 1, 4, 4, 1, 4, 4, 1, 1, 1, 1, 50, 1, 1, 2, 2, 2, 4, 1, 1, 2, 2, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 2, 2, 5, 8, 3, 5, 2, 1, 1, 2, 7, 3, 1, 1, 1, 3, 1, 7, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 4, 1, 1, 1, 3, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 4, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 3, 3, 4, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 3, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 5, 4, 4, 1, 1, 2, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 1, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 12, 1, 1, 1, 1, 1, 1, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 7, 2, 3, 1, 1, 2, 3, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 3, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 3, 1, 1, 4, 1, 3, 2, 2, 2, 1, 1, 3, 1, 2, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 6, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import stop_words\n",
    "bow = get_bow_from_docs([\n",
    "        #'www.coursereport.com_ironhack.html',\n",
    "        #'en.wikipedia.org_Data_analysis.html',\n",
    "        'www.lipsum.com.html'\n",
    "    ],\n",
    "    stop_words.ENGLISH_STOP_WORDS\n",
    ")\n",
    "\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any problem in the output? How do you improve the output?\n",
    "\n",
    "A good way to improve your codes is to look into the HTML data sources and try to understand where the messy output came from. A good data analyst always learns about the data in depth in order to perform the job well.\n",
    "\n",
    "Spend 20-30 minutes to improve your functions or until you feel you are good at string operations. This lab is just a practice so you don't need to stress yourself out. If you feel you've practiced enough you can stop and move on the next challenge question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
